#### Mysql数据查找的执行顺序
建立连接->检查权限->查询缓存->解析器->分析器(词法分析，语法分析)->优化器(适合的索引，多表关联时候适合的关联顺序)->权限检查(表，字段的权限)->调用表相应的存储引擎的api接口获取一行数据->将获取到的数据保存到结果集，直到遍历到表的最后一行->将结果集返回给客户端

###事务隔离级别

4种：非提交读，会产生脏读，提交读,但是不可重复度，提交读，但是会产生幻读，innodb是通过间隙锁来解决幻读的问题，序列化，但是对性能影响较大

查看当前的锁隔离级别

``
SELECT @@tx_isolation;
``

修改隔离级别

``
SET global.tx_isolation = 'READ-COMMITTED'
``

Read Uncommitted,Read Committed,Repeatable Read,Serializable

set global transaction isolation level read committed;
set session transaction isolation level read committed; 

提交读会产生不可重复读的原因是:第一次读取时候，其他事务写的数据还未提交，第二次读取的时候读取到其他事务提交的数据，所以导致两次的读取不一致

在可重复度隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在"当前读"才会出现。

行锁只能锁住行，但是新插入的数据如果是数据之间的"间隙"，就需要引入间隙锁来解决。

幻读的意思是读不到的数据并不代表它不存在，例如某个数据不存在，然后做插入操作，但是插入操作报错，或者删除一条不存在的数据，然后其他事务插入数据报锁等待，这是因为删除一条不存在的数据产生了间隙锁。
解决办法是对读取的数据加锁(FOR UPDATE),另外如果是范围查找的话，数据库本身是有间隙锁的，也可以解决这种问题。

发生锁等待的情况：这个事务需要写的数据，另外一个事务也在写，但是还没提交
发生死锁的情况：两个事务当前已经写但是还未提交的数据，是另外事务下次要写的数据,数据库本身是有死锁检测的，如果死锁则将持有最少排他锁的事务进行回滚来达到解锁的目的，同时数据库还有锁等待超时机制。

innodb的mvcc除了比较创建的txid和删除的txid之外，还需要比较活跃事务列表，满足条件的数据，还需要去热点视图check,当前事务是TX1002,
如果有找到TX1001的数据，那么TX001的数据在当前事务开始之前是否已经提交，如果已经提交，那么可以读取，如果没有提交，则需要剔除，
另外已经提交了，可以读取，那还要看当前的事务隔离级别，是提交读，还是可重复读，如果是可重复读，那么就不能读取，如果是提交读，那么可以读取。

在可重复读的情况下，视图是在事务开始时候创建的，在可提交读的情况下，视图是在开始第一个sql语句的时候创建的。未提交读情况下，直接返回最新的数据，没有视图的概念。

每条记录在更新的时候，都会记录一条回滚操作，每个操作都可以通过回滚操作得到原始状态的值。

不用时刻启动的事务会有不同的read-view.同一条记录在系统中会存在多个版本，就是数据库的多版本并发控制。

#### memory存储引擎数据是在内存，但是表结构会本地磁盘化的

#### 如何解决数据表的在线修改

* 创建一个新表
* INSERT INTO new_table SELECT * FROM table WHERE id > xxx AND id < xxx
* 一直到没有数据可以操作的时候，将原表删除，新表改名字


#### mysql压测的工具ab/http_load

#### 创建字段不建议使用允许null，坑多多
1 占用空间
2 数据库有许多对null的特殊处理
3 对索引不友好
4 导致唯一索引失效
5 不属于任何一个数据类型，不能运算，对程序也不不友好
6 COUNT(*)不管字段为什么，统计存在的行，单如果是字段统计则统计不到为null的行


#### timestamp和datetime的区别
timestamp内部存储的是时间戳,所以占用的空间要更小，但是得到的时间会根据时区的不同变化，而且允许的时间范围要小的多[1970-01-01 08:00:01  ~ 2038-01-19 03:14:07]

#### varchar 和 char的不同
varchar虽然相对于char会使用更少的空间存储，但事实上，它额外需要1-2个字节来保存字符串的长度，另外如果在做update操作的时候，如果新值比原来的值要大，
存储引擎要通过分页来使数据能够存储得下。

如果数据的最大长度比平均长度要大很多，且数据不是频繁更新的，碎片不是问题；如果使用了utf8这样的复杂字符集，每个字符都使用了不同的长度进行存储。这些情况
使用varchar更合适。

#### blob和text
当这两个类型的值太大时，存储引擎会使用专门的"外部"区域来进行存储，此时每个值在行内需要1-4个字节存储一个指针。

bolb和text的区别是，blob存储的是二进制数据，没有排序规则和字符集。


#### 选择标识符
为标识列选择合适的数据类型非常重要。所谓标识列也就是标识这样数据的列，比如用作join的这些列，这些列要尽可能的使用简单的的数据类型，比如整数，且要保证用来关联的列的数据类型是一致的。

对于完全随机的字符串，要特别注意，例如MD5,sha1或者uuid产生的字符串。这些函数生成新值会任意分布在很大的磁盘空间，这会导致insert和select语句都会很慢，会导致页分裂，磁盘随机访问，以及产生聚簇索引碎片。

#### 反范式的优点

* 所有数据都在一张表里，避免了关联查询。


#### 修改大表使用的技巧

* 在不提供服务的机器上执行alter table操作，然后进行主备切换
* 影子拷贝。
* 另外对于一些只会修改表结构而不会修改数据的情况，可以通过这样的方式，比如修改默认值:
ALTER TABLE table_name ALTER COLUMN column_name SET default = ''
* 创建一个具有相同结构的新表，并且做相应的修改
  执行 FLUSH TABLES WITH READ LOCK  关闭所有正在使用的表，并且禁止任何打开
  交换.frm文件
  UNLOCK TABLES

#### mysql的显式锁

FLUSH TABLES WITH READ LOCK 全局锁

LOCK TABLES table_name READ, table_name_1 WRITE #table_name允许所有人读，空间内不允许写，空间外写要等待空间退出,table_name_1允许空间内所有人读写，空间外要等到空间退出
UNLOCK TABLES #退出封闭空间，释放表锁

SELECT ... FOR UPDATE

    如果要确保自己查到的数据是最新的，并且数据只允许自己修改，则适合使用排它锁(X锁),此时其他事务将不能对这些数据再加锁
    For Update 同时会生成行锁和间隙锁。行锁和间隙锁合成next-key lock,锁的区间是前开后闭区间。
    情况如下：
    1 WHERE过滤条件的字段没有索引:锁住所有数据行间隙
    2 WHERE过滤条件的字段有索引: 锁住符合条件的行和相邻的区间
    3 WHERE过滤的行不存在:锁住这个过滤条件的值所在的间隙，比如 WHERE d = 6,这时候锁住的就是d的值(5,10]的间隙。
    注意:WHERE过滤条件的字段没有索引的话，那会导致所有数据和间隙都会锁住；如果有索引的话，那只会锁住符合条件的行和周围的间隙。
    间隙锁和行锁合成next-key lock,锁的区间是前开后闭区间，如上所述。
    4 索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
    5 如果有limit,那么锁住的是过滤出的
    
    这样的数据：
     id | c    | d    |
    +----+------+------+
    |  0 |    0 |    5 |
    |  5 |    5 |    5 |
    | 10 |   10 |   10 |
    | 11 |   11 |   11 |
    | 15 |   15 |   15 |
    | 20 |   20 |   20 |
    | 25 |   25 |   25 |
    | 26 |   26 |   26 」
    
    如果session 1:
        start session;
        select * from t where d=5 for update;
    session 2:
        insert into t values(1, 1, 1); //锁等待
        update t set c = 9 WHERE id = 26; //锁等待
        insert into t values(27, 27, 27);//成功
    
    
SELECT ... LOCK IN SHARE MODE 

    如果要确保自己获取到的数据没有正在被其他事务修改，也就是说确保自己查询到的是最新的数据，并且不允许其他人修改，而且自己也不一定修改数据，因为有可能其他的事务也对这些数据使用了共享锁(S锁)
    
FOR UPDATE相当于一个写操作，在业务繁忙的情况下，如果没有及时commit或者rollback,可能会造成其他事务长时间的等待。
LOCK IN SHARE MODE是对查找到数据加了一个共享锁，它允许其他事务也对该数据上共享锁，但是不能够允许对该数据进行修改，如果不及时commit或者rollback,也可能会造成大量事务等待。
    
Innodb事务的锁等待超时是innodb_lock_wait_timeout变量来控制的



#### ALTER TABLE MODIFY 和 change的区别
change修改列的时候，需要些两次列名，不是很方便，但是如果是修改列的名称，则只能用change.

#### 索引
 索引是存储引擎为了快速找到记录的一种数据结构
 按照数据结构跟类:索引有B-Tree索引，hash索引，空间索引(spatial)，全文索引(fulltext)。
 按照存储的数据划分:聚簇索引，二级索引
 按照类型分类：主键索引，唯一索引，普通索引
 按照索引使用的列：局部索引，单列索引，联合索引
 
 B-tree索引是顺序存储的，所以很适合范围查找和排序。
 
 只有memory引擎支持hash索引，所以我们可以手动创建伪hash索引，比如对url列创建一列额外的hash列，用于存储url的hash值，但是需要自己维护hash值的计算.hash值因为是零散分布的，所以不适合做范围查找，当然也是无序的。存储引擎会对频繁检索的数据，在B-tree的基础上再构建一层hash索引。
 
 索引的优点：
 
 * 大大减少了服务器需要扫描的行数
 * 可以帮助服务器避免排序和临时表(因为B-tree本身就是有序的)
 * 可以避免回表
 * 索引可以将随机IO变为顺序IO

#### 对于大字段创建索引

1 可以只用伪hash索引的方式，但是需要自己维护hash列比较麻烦
2 使用前缀索引，但是会降低索引的选择性，需要计算来确定选择前面几个字段是合适的。mysql无法使用前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描

计算方法是：
   第一步 [制造数据](process.sql)
   第二步: SELECT COUNT(*) AS cnt, url from users GROUP BY url ORDER BY cnt；
   第三步: SELECT COUNT(*) AS cnt, LEFT(url, 20) AS prefix FROM USERS GROUP BY prefix ORDER BY cnt DESC;
   
   当第二步和第三步的值比较接近的时候，就可以了。
   
   第二种计算方式：
   步骤一：先计算数据的唯一性比例: SELECT COUNT(distinct url) / COUNT(url) from users;
   步骤二：使用前缀计算：SELECT COUNT(distinct LEFT(url, 10)) / COUNT(url) from users;
   当使用前缀和计算出来的比例和使用全字段计算出来的比较接近的时候，或者增加前缀的长度，但是唯一性比例不再提高的情况下，就OK了。
 
 #### 选择合适的索引顺序
 
    当不需要考虑排序和分组时，将选择性最高的列放在最前面通常是最好的，这时候索引的作用只是用于优化WHERE条件的查找。性能不只是依赖于所有索引列的选择性，
    也和查询的数据的分布有关系。这样就可能需要按照哪那些运行频率最高的查询来调整索引列的顺序，让这种情况先索引的选择性最高。
    
要确定索引的顺序，需要确定表中值的分布情况：
    SELECT SUM(name = '01'), SUM(age = 12) FROM t1; // 5, 1
根据结果应该将age放到前面，因为age的选择性更高，但是这个只是针对一种值的查询的优化，可能导致其他查询并不是很理想，所以我们想要整体性能比较好，就需要采取平均值的估算策略。

按照这样的方式进行估算:

    SELECT COUNT(DISTINCT name), COUNT(age) FROM t1; // 5, 1
这样得出的结论，可以确定age应该放在最前面，因为它的唯一性更高。

但是这种常用的方法因为数据的值的分布，也有一些特例，比如一个应用里面的会员用户和游客，通常游客的数据会占据绝大多数，所以对于游客数据的查询，可能需要提供单独的查询方式和优化。

innodb的二级索引和聚簇索引很不相同，二级索引的叶子节点存储的不是行指针，而是主键值，这样一方面可以节省空间，另外一方面当数据变更导致出现行移动或者数据页分裂时，不会导致二级索引需要变化，只需要维护好聚簇索引，就可以了。

使用聚簇索引的字段最好是有序的，如果业务里没有这样的字段，那可以使用自增ID，不建议使用uuid这样的字段作为主键(聚簇索引)是因为innodb无法简单的直接将新行插入到索引的最后面，而是需要未新行寻找合适的位置，可能是已有数据的中间位置。这就可能导致页分裂。

#### 覆盖索引

mysql可以使用索引来直接获取列的数据，这种索引叫覆盖索引。

只有b-tree索引能创建覆盖索引，hash、空间、全文索引都不存储索引列的值。
当使用覆盖索引的时候，可以从Explain的Extra列看到from index。

覆盖索引带来的好处：

* 索引条目通常远小于数据行的大小，如果只需要读取索引，那么mysql就会极大的减少数据访问量，这对缓存的负载非常重要，因为这种情况下响应的大部分时间话费在数据拷贝上。对于IO密集型的应用，索引的数据量更小，可以全部放在内存中，这对MyIsam尤其有用，因为MyIsam会对索引进行压缩。

* 索引是按照列顺序存储的，对于IO密集型的应用，范围查找会比从磁盘中随机读取每一行数据的IO要小的多。

* Myisam在内存中只缓存索引，数据则依赖于操作系统来缓存，因此要访问数据需要一次系统调用，这可能会导致严重的性能问题，如果是访问索引那就要好很多

* Innodb的二级索引在叶子节点保存的是主键值，如果是覆盖索引，就不需要二次查询。

要避免使用重复索引和冗余索引，重复索引肯定是不必要的，但是冗余索引有时候是需要的，比如在一个全部是数字的符合索引上增加一个很大的字符串的列，这可能会导致原来的查询变慢。如果想让两个查询都快，可能会需要冗余索引。

#### mysql一条更新语句是如何执行的
如果对于一个表上的数据哟更新的时候，跟这个表有关的所有的查询缓存都会失效，所以对于频繁更新的表不建议使用查询缓存。
update的执行链路和查询语句的执行链路是一样的。与查询语句不同的是，更新语句涉及两个log模块：redo-log和bin-log
如果数据的每次更新都是直接写入磁盘，那么磁盘需要找到对应的那条记录，然后更新，整个过程的IO成本是比较高的，所以WAL(write-ahead-logging)技术，
即就是先写日志，在写磁盘。当有更新操作的时候，存储引擎会先将记录写入redo-log,然后再写到磁盘，等到不繁忙的时候，再将这条更新写入磁盘。

如果更新操作很多，一旦redo-log满了的时候，存储引擎不得不抽出时间，将redo-log中的部分记录更新到磁盘，再从redo-log中删除记录。redo-log的更新图
![redo-log的更新图](mysql-redo-log.png)
write pos是当前记录的位置，一边写一边后移，写到最后一个文件末尾，就回到第一个文件的开头。check point是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos 和check point之间的之间就是可以用来记录新的操作的空间，如果write pos追上check point,这时候就不能正常工作了，必须要停下，先擦掉一些记录了。

有了redo-log，Innodb就可以保证数据库发生异常重启，之前提交的记录都不对丢失，称为crash-safe.

mysql开始并没有Innodb,只有MyIsam,但是Myisam没有crash-safe的能力，binlog日志只能用于归档。Innodb是另外公司已插件的形式引入的，既然binlog没有crash-safe的能力，所以innodb只能使用另外一套日志系统，也就是redo-log来实现crash-safe的能力。

redo-log和bin-log的不同：
* 前者是innodb特有的，后者是server层实现的，所有引擎都可以使用。
* redo-log记录的是物理日志，也就是在某个数据页上要做什么修改，而bin-log记录的逻辑日志，就是这个语句的原始操作，比如"给ID=2的这行的age+10"
* redo-log是循环写的，空间固定；bin-log是可以追加写的，文件写到一定程度满了，就会切换为下一个文件。

执行器在执行update语句的流程:

1 执行器先从引擎获取ID=2的这样数据。这里ID是主键，引擎依赖聚簇索引，直接从树中找到这一行，如果这一行在内存中，则直接返回；否则，需要从磁盘读入数据，然后再返回

2 执行器拿到引擎返回的行数据，把这个值加1，得到新行再调用引擎接口api写入这行数据。

3 引擎将这行数据跟新到内存中，同时将这个更新操作记录到redo-log里面，此时redo-log处于prepare状态。告知执行器执行完成，随时可以提交事务

4 执行器生成这个操作的binlog,并且把binlog写入磁盘。

5 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo-log改成提交状态，更新完成。
![整个执行过程](innodb的update执行过程.png)

使用两阶段提交主要是为了防止两个日志不一致，导致数据恢复不一致的问题。

#### 适合用业务字段做主键的场景
如果是常规的key-val查询，比较适合用业务逻辑字段做主键

#### 对于不满足联合索引，最左前缀的查询，mysql5.6以后引入了索引下推

#### 普通索引和唯一索引的选择
理论上普通索引回比唯一索引多一次检索，因为要找到不符合条件为止，而唯一索引，找到符合条件的就结束，但是这个检索一般都是在内存中完成的，因为操作系统的内存是按页来存储数据的，所以这个优势可以忽略。

06 Todo.......
09 Todo.......

优化器选择索引的目的是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。除了扫描行数，优化器还会结合是否使用临时表，是否排序等因素。

#### 扫描行数是怎么判断的？
Mysql在真正开始执行语句之前，并不能精确的知道满足这个条件的记录有多少条，而只是根据统计信息来估算记录值。这个统计信息就是索引的区分度。索引上不同的值越多，区分度越高。一个索引上不同的值，我们称之为"基数"。可以使用 show index from table_name 查看索引的基数(Cardinality).

##### mysql怎么得到索引的基数
把整张表取出来一行行统计，代价太高。所以才去采样统计的方式：Innodb会默认选择N个数据页，统计这些页上的基数值，然后取平均，再乘以索引的页数，就得到了基数。如果数据表持续更新，当更新的数达到总数据的1/M的时候，会重新估算。可以通过设置参数"innodb_stats_persistent"来控制统计信息是否持久化，开启的时候N=20,M=10,关闭的时候N=8，M=16.

优化器有时候会根据扫描的行数和是否二级索引，而选择不同的索引，比如二级索引和主键索引都需要扫描很多行，但是二级索引需要二次扫描，所以优化器可能会选择主键索引，这就可能导致选择错误的索引。遇到这种情况。

如果发现explain以后的rows跟预期的出入比较大，可以考虑使用"analyze table t",用来重新统计索引信息。

#### 什么情况下会引发数据库的flush过程？
1  Innodb的redo-log写满了
2  系统内存不够用了。
3  系统空闲的时候，正常flush.
4  服务正常关闭的时候，会把内存的脏页都flush到磁盘上。

#### 删除数据，表文件大小不变。
innodb_file_per_table关闭的时候，数据是保存在共享空间的，即使表删除，空间也不会回收。
这里讨论开启的情况下，通常情况下delete操作只是告诉存储引擎,将磁盘相应的数据行或者数据页标记为可复用状态，磁盘大小是不变的。所以删除数据是会造成空洞的，插入数据页会造成空洞。如果数据是按照递增顺序插入的，那么索引是紧凑的。单如果数据是随机插入的，就可能造成数据页的分裂。

解决这个问题，可以使用: alter table A engine=InnoDB

#### Innodb统计数据行是实时计算的
因为多版本并发控制,不确定数据的具体行数，不得不拿出每一行，进行判断对当前会话是否可见。那么可是使用show table status的结果：TABLE_ROWS吗，不能，因为这是个估算值，误差极大。

COUNT()是一个聚合函数，对于返回的结果集，如果参数不是NULL，累计加1，否则不加。

统计行数的多种方式的效率:COUNT(字段) < COUNT(主键ID) < COUNT(1) < COUNT(*).

#### 三种数据的插入方式：
INSERT INTO;
INSERT IGNORE INTO: 依赖唯一键或者主键判断，有则忽略
REPLACE INTO: 无则插入，有则更新。

#### 排序
排序动作是在内存中完成的，还是需要借助外部排序(磁盘临时文件)，取决于sort_buffer_size配置的大小。
排序分为全字段排序和rowid排序：如果单行的数据量过大，超过了设置的值(max_length_for_sort_data),就会采用rowid,这时候sort_buffer里放入的是主键id和排序字段。排好序后再
根据主键Id去聚簇索引获取数据。可以借助联合索引来避免排序。

获取随机数据的两种方式(适合空洞很少的数据):

    select max(id),min(id) into @M,@N from t ;
    
    set @X= floor((@M-@N+1)*rand() + @N);
    
    select * from t where id >= @X limit 1;

空洞大的数据就会复杂一点：

    select count(*) into @C from t;
    set @Y = floor(@C * rand());
    set @sql = concat("select * from t limit ", @Y, ",1");
    prepare stmt from @sql;
    execute stmt;
    DEALLOCATE prepare stmt;
    
    
#### 如果查询结果只有一条但是却很慢的情况
数据被锁住了，可能是全局锁，表锁，行锁
表锁的情况：SELECT blocking_pid from sys.schema_table_lock_waits 查找持有锁的进程id,KILL掉就可以了。
行锁的情况：select * from sys.innodb_lock_waits where locked_table=`test`.`t` 找到线程ID，KILL就可以。

Todo 20 ....

#### on duplicate key update 适用于主键和唯一键

#### mysql是怎么保证主备一致的
一般slave库会设置成readonly: set global read_only=1;这个只是针对普通账号，设置为只读。不会影响root账号和同步更新的线程，因为同步更新的线程拥有超级权限。

![主备流程图](主备流程图.png)

1 备库B上通过change master 命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog,这个位置包含文件名和日志偏移量

2 在备库B上执行start slave命令，这时候备库会开启两个线程：io_thread和sql_thread.其中io_thread负责与主库建立连接。

3 主库A校验完用户名、密码后，开始按照备库B传过来的位置,从本地读取binlog,发给B.

4 备库B拿到binlog后，写到本地文件，称为中转日志(relay log).

5 sql_thread读取中转日志，解析出日志中的命令，并执行。

后来由于多线程复制方案的引入，sql_thread演化成为多个线程。

binlog有两种格式:statement(记录操作)和row(记录数据操作的数据,默认是这个),或者混合(mixed)。
statement占用空间更小,但是可能会导致主备操作不一致的问题，比如主库和备库执行操作的时候使用的不同的索引。
row不会有这种情况，但是占用空间。
mixed的话，server会自己判断是否会引起主备不一致，如果会就用row,否则statement.
现在越来越多的企业设置的是row,因为磁盘不是问题。

可以通过

    show variables like  '%log_bin%'; //查看是否开启bin-log
如果没有的话，开启:
    
    [mysqld]
    log-bin = /usr/local/var/mysql/log/mysql-bin.log
    expire-logs-days = 1
    max-binlog-size = 10M
    server-id = 1
查看bin-log:
    
    show binlog events in 'mysql-bin.000001';//针对statement
    mysqlbinlog -vv /usr/local/var/mysql/log/mysql-bin.000001 --start-position=1227
    
    
主备结构有M-S结构和双M-结构，也就是两台机器之间互为主备，这时候需要解决循环拷贝的问题：

1 主备必须设置为不同的server-id
2 备库接收到主库的bin-log，才重放的时候，生成和主库一样的server-id.
3 每个库在收到自己的主库同步过来的bin-log后，先判断server-id,如果跟自己的相同，就表示这个日志是自己生成的，直接丢弃。

如果主备的系统时间不一致，会导致主备延迟的值不准么？
    
    不会，因为备库连接主库的时候，会通过:SELECT UNIX_TIMESTAMP(), 获取主库时间，如果主库和备库的时间不一致，在计算时间差的时候，会自动去掉这个值的。
    
主备延迟产生的原因：

     1 主备网络通信的延迟 
     2 备库消费relay-log的速度。如果备库消费relay-log的速度比主库产生bin-log的速度慢，就会产生主备延迟。
     3 本身机器性能的差异。
     
解决的方式：保证主从对称部署，另外从库上的读请求的压力也会比较大，所以可以一主多从。另外如果一个大事务在主库上执行10分钟，那备库也10分钟，主备延迟至少10分钟。所以要尽量避免大事务。但有一些大事务是不可避免的，比如大表的DDL,这个可以推荐使用go-ost.另外如果备库启动了一个长事务，也会导致主备延迟。


由于主备延迟的存在，所以主备切换的时候，就会有不同的策略

    A 可靠性优先的策略
    
       1 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
       2 把主库 A 改成只读状态，即把 readonly 设置为 true；
       3 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
       4 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
       5 把业务请求切到备库 B。
       
    在步骤2之后，主备都是readonly,系统处于不可写状态。同时步骤3可能会耗费几秒的时间，所以整个过程会造成几秒甚至更长的系统不可用。
    
    B 可用优先性策略
        直接执行4，5，然后执行2
        
    但是这样会造成数据不一致。
    
主从配置的步骤：

    master主库配置同步，slave从库配置同步，master锁表/备份，slave恢复数据，slave启用同步，master解锁
    
   
一主多备情况下，主备切换
    从在找位点的问题，但是原来的原来的互为主备的两个库可能存在数据不同步的问题，导致两个库的位点不同，所以可能需要以下操作：
    1 主动跳过事务：
    
        set global sql_slave_skip_counter=1;
        start slave;
        
    我们需要在从库 B 刚开始接到新主库 A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。
    
    2 设置slave_skip_errors = "1032,1062",忽略错误：
    
       1062 错误是插入数据时唯一键冲突；
       1032 错误是删除数据时找不到行。
       
    这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系,等到主备间的同步关系建立完成，并稳定执行一段时间之后，我们还需要把这个参数设置为空.
    
    3 mysql5.6版本以后引入了GTID
    
        GTID(global transaction identifier)是对于一个已提交事务的全局唯一编号。
        主备切换的时候配置:master_auto_position=1就表示主备关系使用的是GTID.
        
读(从库)写(主库)分离的时候，造成的主库不一致问题，如何解决：
     
     对于数据一致性要求高的读强制走主库，
     如果主备刚刚切换，可以 SELECT Sleep(1),等待一下主备切换
     每次请求前判断主备延迟时间seconds_behind_master=0
     也可以对比位点和对比GTID.
     
#### 如何确定数据库是不是出问题了
    
##### 并发连接和并发查询

你在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询

##### 避免误删操作的建议

1 账号分离
    
    只给业务开发同学DML权限，不给truncate/drop权限。而如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持
    
    即使DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。
    
2 指定操作规范

    在删数据表之前，必须先对表做改名操作。然后，操作一段时间，确保对业务无影响以后再删除这张表.改表明的时候加统一后缀,然后删除表的动作必须通过管理系统执行。管理系统只能删除带固定后缀的表。
    
#### MYSQL的两个kill 命令：

    kill query + 线程ID;
    kill connection + 线程ID; connection可省略，表示断开连接。
    
#### join查询
    如果使用索引使用的NLJ算法。
    小表作为驱动表，且要保证可以使用被驱动表的索引。如果被驱动表没使用索引的情况,explain的结果会看到：Using join buffer (Block Nested Loop)也就是BNL.
    MRR算法，就是按照驱动表关联数据的时候，根据索引定位到满足条件的记录，将Id值放入read_rnd_buffer中进行递增，按照排序后的主键ID到索引中去查找记录，并作为返回结果。MRR算法的优势在于范围查找的时候，可以得到足够多的主键ID。
    Mysql5.6以后的版本引入了BKA算法，
    NLJ算法的执行逻辑是：从驱动表t1,一行行的取出a的值，再到被驱动表t2去做join.也就是说，对于t2来说，每次都是匹配一个值，这时MRR的优势就用不上了。
    
  启用BKA算法：set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
  
  BKA算法就是批量的从驱动表拿出来一部分数据和被驱动表做关联，然后对索引排序，再去到ID主键找数据。
  
#### 哪些情况会用到临时表

1 使用union的情况，使用union all的时候不需要去重，数据是直接发送给客户端的，不需要临时表。

2 Group by 语句会使用临时表：

    select id%10 as m, count(*) as c from user no_cache group by m order by null;
    以上语句的执行顺序：
    1 创建内存临时表，表里有两个字段 m 和 c，主键是 m；
    2 扫描表 user 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x；
        如果临时表中没有主键为 x 的行，就插入一个记录 (x,1);
        如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1；
    3 遍历完成后，再根据字段 m 做排序，得到结果集返回给客户端。
sql语句结尾"order by null"是告诉引擎不需要对搜索结果排序.

不论是内存临时表，还是磁盘临时表，Group By都需要构造一个带唯一索引的表，执行代价都是比较高的。如果表的数据量比较大，group by 语句执行起来就会很慢。

那如果可以保证扫描过程出现的数据是有序的，是不是就可以避免维护这个带唯一索引的临时表。Mysql5.7版本支持了generated column 机制，用来实现列数据的关联更新。
    alter table user1 add column id_other int generated always as(id % 100), add index(id_other);
    但是需要注意的是：id字段不能是自增的，自增的时候会报错:
  之后就需要临时表了：select id_other, count(*) as c from user no_cache group by id_other;
   
这里总结下使用临时表的原则：
1 如果语句执行过程中可以一边读数据，一边直接得到数据，是不需要额外内存的，否则就需要额外的内存。
2 join_buffer是无需数组，sort_buffer是有序数组，临时表是二维表结构。
3 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表

group by 使用的指导原则：

* 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；
* 尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；
* 如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；
* 如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。

#### 造成自增Id不连续的情况
1 唯一键冲突，造成auto_increment已经重新计算，但是值插入失败
2 事务回滚导致auto_increment已经重新计算，但是插入数据回滚
3 当然了删除数据，和插入数据时候传入ID值也会导致不连续。


#### 表物理拷贝
mysql5.6引入了可传输表空间，现在以拷贝user1的数据为user2举例。
1 执行 create table r like t，创建一个相同表结构的空表；
2 执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；
3 执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；
4 在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；
5 执行 unlock tables，这时候 t.cfg 文件会被删除；
6 执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。

#### 分区表和手工分表
前者是server层决定使用哪个分区，后者是业务代码决定使用哪个分区,因此，从引擎层面看是没有差别的。第一次访问分区表的时候，MYSQL需要把所有的表都访问一遍。

MyISAM 分区表使用的分区策略，我们称为通用分区策略（generic partitioning），每次访问分区都由 server 层控制。通用分区策略，是 MySQL 一开始支持分区表的时候就存在的代码，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题。

从 MySQL 5.7.9 开始，InnoDB 引擎引入了本地分区策略（native partitioning）。这个策略是在 InnoDB 内部自己管理打开分区的行为。

MySQL 从 5.7.17 开始，将 MyISAM 分区表标记为即将弃用 (deprecated),从 MySQL 8.0 版本开始，就不允许创建 MyISAM 分区表了，只允许创建已经实现了本地分区策略的引擎。目前来看，只有 InnoDB 和 NDB 这两个引擎支持了本地分区策略。

分区表，在做 DDL 的时候，影响会更大。如果你使用的是普通分表，那么当你在 truncate 一个分表的时候，肯定不会跟另外一个分表上的查询语句，出现 MDL 锁冲突。

小结一下:

1 MySQL 在第一次打开分区表的时候，需要访问所有的分区；
2 在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁；
3 在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区。


select a from t group by a order by null;
select distinct a from t;
这两条语句的执行效率是一样的。